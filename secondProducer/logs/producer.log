INFO  24-03-05 14:22:28[main] [Mainrunningapp:50] - Starting Mainrunningapp using Java 21.0.1 with PID 26888 (D:\GitWorkSpace\kafkaClientProducer\secondProducer\target\classes started by 인포전스 in D:\GitWorkSpace\kafkaClientProducer\secondProducer)
INFO  24-03-05 14:22:28[main] [Mainrunningapp:654] - No active profile set, falling back to 1 default profile: "default"
INFO  24-03-05 14:22:31[main] [TomcatWebServer:109] - Tomcat initialized with port 8081 (http)
INFO  24-03-05 14:22:31[main] [Http11NioProtocol:173] - Initializing ProtocolHandler ["http-nio-8081"]
INFO  24-03-05 14:22:31[main] [ServletWebServerApplicationContext:296] - Root WebApplicationContext: initialization completed in 3306 ms
INFO  24-03-05 14:22:34[main] [Http11NioProtocol:173] - Starting ProtocolHandler ["http-nio-8081"]
INFO  24-03-05 14:22:34[main] [TomcatWebServer:241] - Tomcat started on port 8081 (http) with context path ''
INFO  24-03-05 14:22:34[main] [Mainrunningapp:56] - Started Mainrunningapp in 7.35 seconds (process running for 11.077)
INFO  24-03-05 14:22:39[http-nio-8081-exec-2] [DispatcherServlet:532] - Initializing Servlet 'dispatcherServlet'
INFO  24-03-05 14:22:39[http-nio-8081-exec-2] [DispatcherServlet:554] - Completed initialization in 4 ms
INFO  24-03-05 14:22:40[http-nio-8081-exec-2] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:22:40[http-nio-8081-exec-1] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:22:40[task-1] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:22:40[task-2] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:22:40[task-1] [KafkaProducer:580] - [Producer clientId=producer-2] Instantiated an idempotent producer.
INFO  24-03-05 14:22:40[task-2] [KafkaProducer:580] - [Producer clientId=producer-1] Instantiated an idempotent producer.
INFO  24-03-05 14:22:41[task-2] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:22:41[task-2] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:22:41[task-2] [AppInfoParser:121] - Kafka startTimeMs: 1709616161209
INFO  24-03-05 14:22:41[task-1] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:22:41[task-1] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:22:41[task-1] [AppInfoParser:121] - Kafka startTimeMs: 1709616161219
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-2] [Metadata:287] - [Producer clientId=producer-2] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-1] [Metadata:287] - [Producer clientId=producer-1] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:22:42[task-2] [KafkaProducer:1295] - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:22:42[task-1] [KafkaProducer:1295] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-1] [TransactionManager:505] - [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-2] [TransactionManager:505] - [Producer clientId=producer-2] ProducerId set to 1 with epoch 0
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-1] [KafkaProducerApp:97] - 03/05::02/22/42  Success partition : 0, offset : 1
INFO  24-03-05 14:22:42[kafka-producer-network-thread | producer-2] [KafkaProducerApp:97] - 03/05::02/22/42  Success partition : 0, offset : 0
INFO  24-03-05 14:22:42[task-2] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:22:42[task-2] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:22:42[task-2] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:22:42[task-1] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:22:42[task-1] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:22:42[task-2] [AppInfoParser:83] - App info kafka.producer for producer-1 unregistered
INFO  24-03-05 14:22:42[task-1] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:22:42[http-nio-8081-exec-2] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:22:42[task-1] [AppInfoParser:83] - App info kafka.producer for producer-2 unregistered
INFO  24-03-05 14:22:42[http-nio-8081-exec-1] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:23:09[http-nio-8081-exec-6] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:23:09[task-3] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:23:09[task-3] [KafkaProducer:580] - [Producer clientId=producer-3] Instantiated an idempotent producer.
INFO  24-03-05 14:23:09[task-3] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:23:09[task-3] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:23:09[task-3] [AppInfoParser:121] - Kafka startTimeMs: 1709616189519
INFO  24-03-05 14:23:09[kafka-producer-network-thread | producer-3] [Metadata:287] - [Producer clientId=producer-3] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:23:09[task-3] [KafkaProducer:1295] - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:23:09[kafka-producer-network-thread | producer-3] [TransactionManager:505] - [Producer clientId=producer-3] ProducerId set to 2 with epoch 0
INFO  24-03-05 14:23:09[kafka-producer-network-thread | producer-3] [KafkaProducerApp:97] - 03/05::02/23/09  Success partition : 0, offset : 2
INFO  24-03-05 14:23:09[task-3] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:23:09[task-3] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:23:09[task-3] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:23:09[task-3] [AppInfoParser:83] - App info kafka.producer for producer-3 unregistered
INFO  24-03-05 14:23:09[http-nio-8081-exec-6] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:23:39[http-nio-8081-exec-10] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:23:39[task-4] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:23:39[http-nio-8081-exec-9] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:23:39[task-5] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:23:39[task-5] [KafkaProducer:580] - [Producer clientId=producer-5] Instantiated an idempotent producer.
INFO  24-03-05 14:23:39[task-4] [KafkaProducer:580] - [Producer clientId=producer-4] Instantiated an idempotent producer.
INFO  24-03-05 14:23:39[task-5] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:23:39[task-5] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:23:39[task-5] [AppInfoParser:121] - Kafka startTimeMs: 1709616219554
INFO  24-03-05 14:23:39[task-4] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:23:39[task-4] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:23:39[task-4] [AppInfoParser:121] - Kafka startTimeMs: 1709616219571
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-5] [Metadata:287] - [Producer clientId=producer-5] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-5] [TransactionManager:505] - [Producer clientId=producer-5] ProducerId set to 3 with epoch 0
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-4] [Metadata:287] - [Producer clientId=producer-4] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:23:39[task-5] [KafkaProducer:1295] - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-4] [TransactionManager:505] - [Producer clientId=producer-4] ProducerId set to 4 with epoch 0
INFO  24-03-05 14:23:39[task-4] [KafkaProducer:1295] - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-5] [KafkaProducerApp:97] - 03/05::02/23/39  Success partition : 0, offset : 3
INFO  24-03-05 14:23:39[task-5] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:23:39[task-5] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:23:39[task-5] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:23:39[task-5] [AppInfoParser:83] - App info kafka.producer for producer-5 unregistered
INFO  24-03-05 14:23:39[http-nio-8081-exec-9] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:23:39[kafka-producer-network-thread | producer-4] [KafkaProducerApp:97] - 03/05::02/23/39  Success partition : 0, offset : 4
INFO  24-03-05 14:23:39[task-4] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:23:39[task-4] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:23:39[task-4] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:23:39[task-4] [AppInfoParser:83] - App info kafka.producer for producer-4 unregistered
INFO  24-03-05 14:23:39[http-nio-8081-exec-10] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:24:09[http-nio-8081-exec-5] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:24:09[task-6] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:24:09[task-6] [KafkaProducer:580] - [Producer clientId=producer-6] Instantiated an idempotent producer.
INFO  24-03-05 14:24:09[task-6] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:24:09[task-6] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:24:09[task-6] [AppInfoParser:121] - Kafka startTimeMs: 1709616249500
INFO  24-03-05 14:24:09[kafka-producer-network-thread | producer-6] [Metadata:287] - [Producer clientId=producer-6] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:24:09[task-6] [KafkaProducer:1295] - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:24:09[kafka-producer-network-thread | producer-6] [TransactionManager:505] - [Producer clientId=producer-6] ProducerId set to 5 with epoch 0
INFO  24-03-05 14:24:09[kafka-producer-network-thread | producer-6] [KafkaProducerApp:97] - 03/05::02/24/09  Success partition : 0, offset : 5
INFO  24-03-05 14:24:09[task-6] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:24:09[task-6] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:24:09[task-6] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:24:09[task-6] [AppInfoParser:83] - App info kafka.producer for producer-6 unregistered
INFO  24-03-05 14:24:09[http-nio-8081-exec-5] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:24:39[http-nio-8081-exec-3] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:24:39[task-7] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:24:39[task-7] [KafkaProducer:580] - [Producer clientId=producer-7] Instantiated an idempotent producer.
INFO  24-03-05 14:24:39[task-7] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:24:39[task-7] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:24:39[task-7] [AppInfoParser:121] - Kafka startTimeMs: 1709616279521
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-7] [Metadata:287] - [Producer clientId=producer-7] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-7] [TransactionManager:505] - [Producer clientId=producer-7] ProducerId set to 6 with epoch 0
INFO  24-03-05 14:24:39[task-7] [KafkaProducer:1295] - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:24:39[http-nio-8081-exec-7] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:24:39[task-8] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:24:39[task-8] [KafkaProducer:580] - [Producer clientId=producer-8] Instantiated an idempotent producer.
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-7] [KafkaProducerApp:97] - 03/05::02/24/39  Success partition : 0, offset : 6
INFO  24-03-05 14:24:39[task-7] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:24:39[task-7] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:24:39[task-7] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:24:39[task-7] [AppInfoParser:83] - App info kafka.producer for producer-7 unregistered
INFO  24-03-05 14:24:39[http-nio-8081-exec-3] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:24:39[task-8] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:24:39[task-8] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:24:39[task-8] [AppInfoParser:121] - Kafka startTimeMs: 1709616279586
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-8] [Metadata:287] - [Producer clientId=producer-8] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-8] [TransactionManager:505] - [Producer clientId=producer-8] ProducerId set to 7 with epoch 0
INFO  24-03-05 14:24:39[task-8] [KafkaProducer:1295] - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:24:39[kafka-producer-network-thread | producer-8] [KafkaProducerApp:97] - 03/05::02/24/39  Success partition : 0, offset : 7
INFO  24-03-05 14:24:39[task-8] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:24:39[task-8] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:24:39[task-8] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:24:39[task-8] [AppInfoParser:83] - App info kafka.producer for producer-8 unregistered
INFO  24-03-05 14:24:39[http-nio-8081-exec-7] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:25:09[http-nio-8081-exec-8] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:25:09[task-9] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:25:09[task-9] [KafkaProducer:580] - [Producer clientId=producer-9] Instantiated an idempotent producer.
INFO  24-03-05 14:25:09[task-9] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:25:09[task-9] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:25:09[task-9] [AppInfoParser:121] - Kafka startTimeMs: 1709616309423
INFO  24-03-05 14:25:09[kafka-producer-network-thread | producer-9] [Metadata:287] - [Producer clientId=producer-9] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:25:09[task-9] [KafkaProducer:1295] - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:25:09[kafka-producer-network-thread | producer-9] [TransactionManager:505] - [Producer clientId=producer-9] ProducerId set to 8 with epoch 0
INFO  24-03-05 14:25:09[kafka-producer-network-thread | producer-9] [KafkaProducerApp:97] - 03/05::02/25/09  Success partition : 0, offset : 8
INFO  24-03-05 14:25:09[task-9] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:25:09[task-9] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:25:09[task-9] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:25:09[task-9] [AppInfoParser:83] - App info kafka.producer for producer-9 unregistered
INFO  24-03-05 14:25:09[http-nio-8081-exec-8] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:25:39[http-nio-8081-exec-4] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:25:39[task-10] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:25:39[task-10] [KafkaProducer:580] - [Producer clientId=producer-10] Instantiated an idempotent producer.
INFO  24-03-05 14:25:39[http-nio-8081-exec-1] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:25:39[task-11] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:25:39[task-11] [KafkaProducer:580] - [Producer clientId=producer-11] Instantiated an idempotent producer.
INFO  24-03-05 14:25:39[task-10] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:25:39[task-10] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:25:39[task-10] [AppInfoParser:121] - Kafka startTimeMs: 1709616339488
INFO  24-03-05 14:25:39[task-11] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:25:39[task-11] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:25:39[task-11] [AppInfoParser:121] - Kafka startTimeMs: 1709616339492
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-10] [Metadata:287] - [Producer clientId=producer-10] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-10] [TransactionManager:505] - [Producer clientId=producer-10] ProducerId set to 9 with epoch 0
INFO  24-03-05 14:25:39[task-10] [KafkaProducer:1295] - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-11] [Metadata:287] - [Producer clientId=producer-11] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-11] [TransactionManager:505] - [Producer clientId=producer-11] ProducerId set to 10 with epoch 0
INFO  24-03-05 14:25:39[task-11] [KafkaProducer:1295] - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-10] [KafkaProducerApp:97] - 03/05::02/25/39  Success partition : 0, offset : 9
INFO  24-03-05 14:25:39[task-10] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:25:39[kafka-producer-network-thread | producer-11] [KafkaProducerApp:97] - 03/05::02/25/39  Success partition : 0, offset : 10
INFO  24-03-05 14:25:39[task-10] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:25:39[task-10] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:25:39[task-10] [AppInfoParser:83] - App info kafka.producer for producer-10 unregistered
INFO  24-03-05 14:25:39[http-nio-8081-exec-4] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:25:39[task-11] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:25:39[task-11] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:25:39[task-11] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:25:39[task-11] [AppInfoParser:83] - App info kafka.producer for producer-11 unregistered
INFO  24-03-05 14:25:39[http-nio-8081-exec-1] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:26:09[http-nio-8081-exec-2] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:26:09[task-12] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:26:09[task-12] [KafkaProducer:580] - [Producer clientId=producer-12] Instantiated an idempotent producer.
INFO  24-03-05 14:26:09[task-12] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:26:09[task-12] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:26:09[task-12] [AppInfoParser:121] - Kafka startTimeMs: 1709616369557
INFO  24-03-05 14:26:09[kafka-producer-network-thread | producer-12] [Metadata:287] - [Producer clientId=producer-12] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:26:09[kafka-producer-network-thread | producer-12] [TransactionManager:505] - [Producer clientId=producer-12] ProducerId set to 11 with epoch 0
INFO  24-03-05 14:26:09[task-12] [KafkaProducer:1295] - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:26:09[kafka-producer-network-thread | producer-12] [KafkaProducerApp:97] - 03/05::02/26/09  Success partition : 0, offset : 11
INFO  24-03-05 14:26:09[task-12] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:26:09[task-12] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:26:09[task-12] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:26:09[task-12] [AppInfoParser:83] - App info kafka.producer for producer-12 unregistered
INFO  24-03-05 14:26:09[http-nio-8081-exec-2] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:26:39[http-nio-8081-exec-6] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:26:39[http-nio-8081-exec-9] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:26:39[task-13] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:26:39[task-13] [KafkaProducer:580] - [Producer clientId=producer-13] Instantiated an idempotent producer.
INFO  24-03-05 14:26:39[task-14] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:26:39[task-14] [KafkaProducer:580] - [Producer clientId=producer-14] Instantiated an idempotent producer.
INFO  24-03-05 14:26:39[task-13] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:26:39[task-13] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:26:39[task-13] [AppInfoParser:121] - Kafka startTimeMs: 1709616399497
INFO  24-03-05 14:26:39[task-14] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:26:39[task-14] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:26:39[task-14] [AppInfoParser:121] - Kafka startTimeMs: 1709616399501
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-14] [Metadata:287] - [Producer clientId=producer-14] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:26:39[task-14] [KafkaProducer:1295] - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-14] [TransactionManager:505] - [Producer clientId=producer-14] ProducerId set to 12 with epoch 0
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-14] [KafkaProducerApp:97] - 03/05::02/26/39  Success partition : 0, offset : 12
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-13] [Metadata:287] - [Producer clientId=producer-13] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:26:39[task-14] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-13] [TransactionManager:505] - [Producer clientId=producer-13] ProducerId set to 13 with epoch 0
INFO  24-03-05 14:26:39[task-13] [KafkaProducer:1295] - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:26:39[task-14] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:26:39[task-14] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:26:39[task-14] [AppInfoParser:83] - App info kafka.producer for producer-14 unregistered
INFO  24-03-05 14:26:39[http-nio-8081-exec-9] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:26:39[kafka-producer-network-thread | producer-13] [KafkaProducerApp:97] - 03/05::02/26/39  Success partition : 0, offset : 13
INFO  24-03-05 14:26:39[task-13] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:26:39[task-13] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:26:39[task-13] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:26:39[task-13] [AppInfoParser:83] - App info kafka.producer for producer-13 unregistered
INFO  24-03-05 14:26:39[http-nio-8081-exec-6] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:27:09[http-nio-8081-exec-10] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:27:09[task-15] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:27:09[task-15] [KafkaProducer:580] - [Producer clientId=producer-15] Instantiated an idempotent producer.
INFO  24-03-05 14:27:09[task-15] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:27:09[task-15] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:27:09[task-15] [AppInfoParser:121] - Kafka startTimeMs: 1709616429457
INFO  24-03-05 14:27:09[kafka-producer-network-thread | producer-15] [Metadata:287] - [Producer clientId=producer-15] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:27:09[kafka-producer-network-thread | producer-15] [TransactionManager:505] - [Producer clientId=producer-15] ProducerId set to 14 with epoch 0
INFO  24-03-05 14:27:09[task-15] [KafkaProducer:1295] - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:27:09[kafka-producer-network-thread | producer-15] [KafkaProducerApp:97] - 03/05::02/27/09  Success partition : 0, offset : 14
INFO  24-03-05 14:27:09[task-15] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:27:09[task-15] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:27:09[task-15] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:27:09[task-15] [AppInfoParser:83] - App info kafka.producer for producer-15 unregistered
INFO  24-03-05 14:27:09[http-nio-8081-exec-10] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:27:39[http-nio-8081-exec-5] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:27:39[http-nio-8081-exec-3] [TopicsController:56] - 토픽이름 : firsttopic
INFO  24-03-05 14:27:39[task-16] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:27:39[task-17] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:27:39[task-16] [KafkaProducer:580] - [Producer clientId=producer-16] Instantiated an idempotent producer.
INFO  24-03-05 14:27:39[task-17] [KafkaProducer:580] - [Producer clientId=producer-17] Instantiated an idempotent producer.
INFO  24-03-05 14:27:39[task-16] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:27:39[task-16] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:27:39[task-16] [AppInfoParser:121] - Kafka startTimeMs: 1709616459464
INFO  24-03-05 14:27:39[task-17] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:27:39[task-17] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:27:39[task-17] [AppInfoParser:121] - Kafka startTimeMs: 1709616459465
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-17] [Metadata:287] - [Producer clientId=producer-17] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-16] [Metadata:287] - [Producer clientId=producer-16] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-17] [TransactionManager:505] - [Producer clientId=producer-17] ProducerId set to 15 with epoch 0
INFO  24-03-05 14:27:39[task-17] [KafkaProducer:1295] - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-16] [TransactionManager:505] - [Producer clientId=producer-16] ProducerId set to 16 with epoch 0
INFO  24-03-05 14:27:39[task-16] [KafkaProducer:1295] - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-16] [KafkaProducerApp:97] - 03/05::02/27/39  Success partition : 0, offset : 15
INFO  24-03-05 14:27:39[kafka-producer-network-thread | producer-17] [KafkaProducerApp:97] - 03/05::02/27/39  Success partition : 0, offset : 16
INFO  24-03-05 14:27:39[task-17] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:27:39[task-16] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:27:39[task-16] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:27:39[task-17] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:27:39[task-16] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:27:39[task-17] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:27:39[task-16] [AppInfoParser:83] - App info kafka.producer for producer-16 unregistered
INFO  24-03-05 14:27:39[http-nio-8081-exec-5] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:27:39[task-17] [AppInfoParser:83] - App info kafka.producer for producer-17 unregistered
INFO  24-03-05 14:27:39[http-nio-8081-exec-3] [TopicsController:62] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:28:09[http-nio-8081-exec-7] [TopicsController:71] - 토픽이름 : firsttopic
INFO  24-03-05 14:28:09[task-18] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:28:09[task-18] [KafkaProducer:580] - [Producer clientId=producer-18] Instantiated an idempotent producer.
INFO  24-03-05 14:28:09[task-18] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:28:09[task-18] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:28:09[task-18] [AppInfoParser:121] - Kafka startTimeMs: 1709616489407
INFO  24-03-05 14:28:09[kafka-producer-network-thread | producer-18] [Metadata:287] - [Producer clientId=producer-18] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:28:09[kafka-producer-network-thread | producer-18] [TransactionManager:505] - [Producer clientId=producer-18] ProducerId set to 17 with epoch 0
INFO  24-03-05 14:28:09[task-18] [KafkaProducer:1295] - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:28:09[kafka-producer-network-thread | producer-18] [KafkaProducerApp:97] - 03/05::02/28/09  Success partition : 0, offset : 17
INFO  24-03-05 14:28:09[task-18] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:28:09[task-18] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:28:09[task-18] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:28:09[task-18] [AppInfoParser:83] - App info kafka.producer for producer-18 unregistered
INFO  24-03-05 14:28:09[http-nio-8081-exec-7] [TopicsController:77] - 프로듀서가 받음 : {"coid":23,"cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpna":"[hg] 테스트 시연"}
INFO  24-03-05 14:28:17[http-nio-8081-exec-8] [TopicsController:56] - 토픽이름 : fifthtopic
INFO  24-03-05 14:28:17[task-19] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:28:17[task-19] [KafkaProducer:580] - [Producer clientId=producer-19] Instantiated an idempotent producer.
INFO  24-03-05 14:28:17[task-19] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:28:17[task-19] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:28:17[task-19] [AppInfoParser:121] - Kafka startTimeMs: 1709616497451
INFO  24-03-05 14:28:17[kafka-producer-network-thread | producer-19] [Metadata:287] - [Producer clientId=producer-19] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:28:17[kafka-producer-network-thread | producer-19] [TransactionManager:505] - [Producer clientId=producer-19] ProducerId set to 18 with epoch 0
INFO  24-03-05 14:28:17[task-19] [KafkaProducer:1295] - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:28:17[kafka-producer-network-thread | producer-19] [KafkaProducerApp:97] - 03/05::02/28/17  Success partition : 0, offset : 0
INFO  24-03-05 14:28:17[task-19] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:28:17[task-19] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:28:17[task-19] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:28:17[task-19] [AppInfoParser:83] - App info kafka.producer for producer-19 unregistered
INFO  24-03-05 14:28:17[http-nio-8081-exec-8] [TopicsController:62] - 프로듀서가 받음 : {"rlsq":2,"coid":"H2","cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpsq":0,"contactLtId":"85aecd05-21b5-46a1-86f3-357f252d10a0","didt":"2023/11/29 20:51:15","dirt":6,"dict":0,"contactId":"83b85d7ff68cb7f0b7b3c59212abefff","hubId":111}
INFO  24-03-05 14:28:18[http-nio-8081-exec-4] [TopicsController:56] - 토픽이름 : fifthtopic
INFO  24-03-05 14:28:18[task-20] [ProducerConfig:370] - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  24-03-05 14:28:18[task-20] [KafkaProducer:580] - [Producer clientId=producer-20] Instantiated an idempotent producer.
INFO  24-03-05 14:28:18[task-20] [AppInfoParser:119] - Kafka version: 3.6.1
INFO  24-03-05 14:28:18[task-20] [AppInfoParser:120] - Kafka commitId: 5e3c2b738d253ff5
INFO  24-03-05 14:28:18[task-20] [AppInfoParser:121] - Kafka startTimeMs: 1709616498037
INFO  24-03-05 14:28:18[kafka-producer-network-thread | producer-20] [Metadata:287] - [Producer clientId=producer-20] Cluster ID: hTT0y-0FTM-p4rZrdMGPwg
INFO  24-03-05 14:28:18[kafka-producer-network-thread | producer-20] [TransactionManager:505] - [Producer clientId=producer-20] ProducerId set to 19 with epoch 0
INFO  24-03-05 14:28:18[task-20] [KafkaProducer:1295] - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
INFO  24-03-05 14:28:18[kafka-producer-network-thread | producer-20] [KafkaProducerApp:97] - 03/05::02/28/18  Success partition : 0, offset : 1
INFO  24-03-05 14:28:18[task-20] [Metrics:693] - Metrics scheduler closed
INFO  24-03-05 14:28:18[task-20] [Metrics:697] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  24-03-05 14:28:18[task-20] [Metrics:703] - Metrics reporters closed
INFO  24-03-05 14:28:18[task-20] [AppInfoParser:83] - App info kafka.producer for producer-20 unregistered
INFO  24-03-05 14:28:18[http-nio-8081-exec-4] [TopicsController:62] - 프로듀서가 받음 : {"rlsq":3,"coid":"H2","cpid":"97e6b32d-c266-4d33-92b4-01ddf33898cd","cpsq":666,"contactLtId":"85aecd05-21b5-46a1-86f3-357f252d10a0","didt":"2023/11/29 20:51:14","dirt":6,"dict":0,"contactId":"0b241f9bef1df80679bfba58582c8505","hubId":0}
